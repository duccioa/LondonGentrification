{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure all necessary packages have been installed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree #for processing XML documents\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.collections import PatchCollection\n",
    "from mpl_toolkits.basemap import Basemap #for mapping\n",
    "from shapely.geometry import Point, Polygon, MultiPoint, MultiPolygon \n",
    "from shapely.prepared import prep #for processing shapefiles to make operations quicker\n",
    "from pysal.esda.mapclassify import Natural_Breaks as nb\n",
    "from descartes import PolygonPatch #to map polygons using matplotlib\n",
    "import fiona #for reading shapefiles\n",
    "from itertools import chain\n",
    "import pyproj #for converting coordinate systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ordance Survey Postcode Files Information</b>\n",
    "\n",
    "- Several separate csv files split by postcode district\n",
    "- Inner London postcode districts include: \n",
    "    - EC, WC, E, N, NW, SE, SW, W\n",
    "- Outer London postcode districts include: \n",
    "    - BR: Bromley, CR: Croydon, DA: Dartford, EN: Enfield, HA: Harrow\n",
    "        IG: Ilford, KT: Kingston, RM: Romford, SM: Sutton, TW: Twickenham\n",
    "        UB: Uxbridge, WD: Watford\n",
    "- The file contains the following fields:\n",
    " - <i>PC Postcode\n",
    " - PQ Positional_quality_indicator\t\n",
    " - EA Eastings\n",
    " - NO Northings\n",
    " - CY Country_code\n",
    " - RH NHS_regional_HA_code\t\n",
    " - LH NHS_HA_code\t\n",
    " - CC Admin_county_code\n",
    " - DC Admin_district_code\t\n",
    " - WC Admin_ward_code</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Clear Column Headers for Postcode Files\n",
    "pc_headers = ['Postcode', 'Positional_quality_indicator', 'E', \n",
    "              'N', 'Country_code', 'NHS_regional_HA_code',\n",
    "              'NHS_HA_code', 'Admin_county_code', 'Admin_district_code', \n",
    "              'Admin_ward_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Code to import and join all postcode tables together for London\n",
    "\n",
    "#List of postcode districts that apply to London\n",
    "Lon_pc_dis_lst = ['ec', 'wc', 'e', 'n', 'nw', 'se', 'sw', 'w', 'br', 'cr', \n",
    "              'da', 'en', 'ha', 'ig', 'kt', 'rm', 'sm', 'tw', 'ub', 'wd']\n",
    "\n",
    "#Generate list of file directories for concatenation\n",
    "files_lst = []\n",
    "direct = \"London_Postcodes_Data\\\\\"\n",
    "\n",
    "for x in Lon_pc_dis_lst:\n",
    "    files_lst.append( direct + x +'.csv')\n",
    "    \n",
    "Lon_pc_df = pd.concat([pd.read_csv(f, header=None, names=pc_headers) for f in files], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Import dataframe </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Clear Column headers for imported dataset (make sure to channge to suit the current dataset! use 'Postcode' for postcode field)\n",
    "pp_headers = ['Transaction_ID', 'Price', 'Transfer_Date', 'Postcode', \n",
    "              'Property_Type', 'Old_New', 'Duration','PAON', 'SAON', \n",
    "              'Street', 'Locality', 'Town_City','District','County', 'PPD_Category_Type', 'Record_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import datadrame (make sure to change the file name!)\n",
    "df=pd.read_csv('Data\\Complete_PP_2015.csv', header=0, names=pp_headers)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Dataset specific cleaning operations (remove if not needed)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert date column to date format\n",
    "df['Transfer_Date'] = pd.to_datetime(df['Transfer_Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Join postcode information (which include coordinates) using the dataframe's 'Postcode' field</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Join easting and northing values to the existing dataframe 'df'\n",
    "df_pc = df.merge(Lon_pc_df, on='Postcode', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Subset the dataframe to include only those values which the London postcode table was joined to</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add boolean field - True if a London postcode was identified\n",
    "df_pc['London'] = df_pc.E.notnull()\n",
    "\n",
    "#Create new dataframe with only London records\n",
    "df_pc_London = df_pc.loc[df_pc.London == True, :]\n",
    "\n",
    "#Make into csv\n",
    "df_pc_London[['Transaction_ID','E','N']].to_csv('Data\\BNG.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Convert eastings and northings to latitide and lonitude for mapping </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Claire\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\ipykernel\\__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Claire\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\ipykernel\\__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Convert BNG Eastings and Northings to WGS84 Lat and lon\n",
    "\n",
    "wgs84=pyproj.Proj(\"+init=EPSG:4326\") # LatLon with WGS84 datum used by GPS units and Google Earth\n",
    "osgb36=pyproj.Proj(\"+init=EPSG:27700\") # UK Ordnance Survey, 1936 datum\n",
    "\n",
    "#Convert easting and norththing colloums to an array to allor pyproj.transform operation to work\n",
    "E_N_array = df_pc_London.as_matrix(columns=['E', 'N'])\n",
    "\n",
    "x, y = WGS84_x, WGS84_y = pyproj.transform(osgb36, wgs84, E_N_array[:,0], E_N_array[:,1])\n",
    "\n",
    "#Put back into dataframe\n",
    "\n",
    "df_pc_London['lon'] = x\n",
    "\n",
    "df_pc_London['lat'] = y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code following tutorial at: http://sensitivecities.com/so-youd-like-to-make-a-map-using-python-EN.html#.Vwon1fkrKUk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Open shapefile with Fiona and get some data out of it in order to set up the basemap</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract map boundaries\n",
    "#Calculated the extent, width and height of our basemap\n",
    "\n",
    "shp = fiona.open('data/london_wards.shp')\n",
    "bds = shp.bounds\n",
    "shp.close()\n",
    "extra = 0.01\n",
    "ll = (bds[0], bds[1])\n",
    "ur = (bds[2], bds[3])\n",
    "coords = list(chain(ll, ur))\n",
    "w, h = coords[2] - coords[0], coords[3] - coords[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Set up the basemap</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(649,\n",
       " 5,\n",
       " [-0.5103750689005356, 51.28676016315085, 0.0, 0.0],\n",
       " [0.3340155643740321, 51.691874116909894, 0.0, 0.0],\n",
       " <matplotlib.collections.LineCollection at 0x43edfc18>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a basemap instance to plot maps on\n",
    "\n",
    "m = Basemap(\n",
    "    projection = 'tmerc',\n",
    "    lon_0 =-2,\n",
    "    lat_0=49.,\n",
    "    ellps = 'WGS84',\n",
    "    llcrnrlon=coords[0] - extra * w,\n",
    "    llcrnrlat=coords[1] - extra + 0.01 * h,\n",
    "    urcrnrlon=coords[2] + extra * w,\n",
    "    urcrnrlat=coords[3] + extra +0.01* h,\n",
    "    lat_ts=0,\n",
    "    resolution='i',\n",
    "    suppress_ticks = True)\n",
    "\n",
    "m.readshapefile(\n",
    "    'data/london_wards',\n",
    "    'london',\n",
    "    color = 'none',\n",
    "    zorder=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Set up a map dataframe</b>\n",
    "\n",
    "map_points weries was creates by passing latitude and longitude values to Basemap instance\n",
    "this converts coordinates from lon and lat degrees to map projection coordinates\n",
    "df_map dataframe now contains columns holding:\n",
    "\n",
    "     a polygon for each ward in shapefile\n",
    "     its description\n",
    "     its area in square metres\n",
    "     its area in square kilometres\n",
    "    \n",
    "Also prepared a geometry object from combined wards polygons to speed up membership checking operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_map = pd.DataFrame({\n",
    "        'poly':[Polygon(xy) for xy in m.london],\n",
    "        'ward_name':[ward['NAME'] for ward in m.london_info]})\n",
    "\n",
    "df_map['area_m'] = df_map['poly'].map(lambda x: x.area)\n",
    "\n",
    "df_map['area_km'] = df_map['area_m']/100000\n",
    "\n",
    "#Create point objects in map coordinates from dataframe lon and lat values\n",
    "\n",
    "map_points = pd.Series(\n",
    "    [Point(m(mapped_x, mapped_y)) for mapped_x, mapped_y in zip(df_pc_London['lon'], df_pc_London['lat'])])\n",
    "plaque_points = MultiPoint(list(map_points.values))\n",
    "wards_polygon = prep(MultiPolygon(list(df_map['poly'].values)))\n",
    "\n",
    "# Calculate points that fall within the London boundary\n",
    "ldn_points = filter(wards_polygon.contains, plaque_points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Pre-prepared functions to generate map color ramps easily </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def colorbar_index(ncolors, cmap, labels=None, **kwargs):\n",
    "    \"\"\"\n",
    "    This is a convenience function to stop you making off-by-one errors\n",
    "    Takes a standard colour ramp, and discretizes it,\n",
    "    then draws a colour bar with correctly aligned labels\n",
    "    \"\"\"\n",
    "    cmap = cmap_discretize(cmap, ncolors)\n",
    "    mappable =  cm.ScalarMappable(cmap=cmap)\n",
    "    mappable.set_array([])\n",
    "    mappable.set_clim(-0.5, ncolors+0.5)\n",
    "    colorbar = plt.colorbar(mappable, **kwargs)\n",
    "    colorbar.set_ticks(np.linspace(0, ncolors, ncolors))\n",
    "    colorbar.set_ticklabels(range(ncolors))\n",
    "    if labels:\n",
    "        colorbar.set_ticklabels(labels)\n",
    "    return colorbar\n",
    "\n",
    "def cmap_discretize(cmap, N):\n",
    "    \"\"\"\n",
    "    Return a discrete colormap from the continuous colormap cmap.\n",
    "\n",
    "        cmap: colormap instance, eg. cm.jet. \n",
    "        N: number of colors.\n",
    "\n",
    "    Example\n",
    "        x = resize(arange(100), (5,100))\n",
    "        djet = cmap_discretize(cm.jet, 5)\n",
    "        imshow(x, cmap=djet)\n",
    "\n",
    "    \"\"\"\n",
    "    if type (cmap) == str:\n",
    "        cmap = get_cmap(cmap)\n",
    "    colors_i = np.concatenate((np.linspace(0,1.,N), (0.,0.,0.,0.)))\n",
    "    colors_rgba = cmap (colors_i)\n",
    "    indices = np.linspace(0,1.,N + 1)\n",
    "    cdict = {}\n",
    "    for ki, key in enumerate(('red','green','blue')):\n",
    "        cdict[key] = [(indices[i], colors_rgba[i-1,ki], colors_rgba[i,ki]) for i in xrange(N+1)]\n",
    "    return matplotlib.colors.LinearSegmentedColormap(cmap.name + \"_%d\" % N, cdict, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot Density Map / Scatter Plot\n",
    "\n",
    "<b> Code to make a dot-density map (matplotlib scatter plot on the ward polygons which are converted to 'patches') </b>\n",
    "\n",
    "Change titles to whatever is most appropriate for your own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Making a scatter plot\n",
    "df_map['patches'] = df_map['poly'].map(lambda x: PolygonPatch(x,\n",
    "                                                             fc='#555555',\n",
    "                                                             ec='#787878', lw=.25, alpha=.9,\n",
    "                                                             zorder=4))\n",
    "plt.clf()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, axisbg='w', frame_on=False)\n",
    "\n",
    "# we don't need to pass points to m() because we calculated using map_points and shapefile polygons\n",
    "dev = m.scatter(\n",
    "    [geom.x for geom in ldn_points],\n",
    "    [geom.y for geom in ldn_points],\n",
    "    5, marker='o', lw=.25,\n",
    "    facecolor='#33ccff', edgecolor='w',\n",
    "    alpha=0.9, antialiased=True,\n",
    "    label='Price Paid Points', zorder=3)\n",
    "\n",
    "# plot boroughs by adding the PatchCollection to the axes instance\n",
    "ax.add_collection(PatchCollection(df_map['patches'].values, match_original=True))\n",
    "\n",
    "#Add copyright and source data info\n",
    "\n",
    "smallprint = ax.text(\n",
    "    1.03, 0,\n",
    "    'Data From: %s\\nContains Ordnance Survey data\\n$\\copyright$ Crown copyright and database right etc',\n",
    "    ha='right', va='bottom',\n",
    "    size=4,\n",
    "    color='#555555',\n",
    "    transform=ax.transAxes)\n",
    "\n",
    "# Draw a map scale\n",
    "\n",
    "m.drawmapscale(\n",
    "    coords[0] + 0.08, coords[1] + 0.015,\n",
    "    coords[0], coords[1],\n",
    "    10.,\n",
    "    barstyle = 'fancy', labelstyle='simple',\n",
    "    fillcolor1='w', fillcolor2 = '#555555',\n",
    "    fontcolor='#555555',\n",
    "    zorder=5)\n",
    "\n",
    "plt.title('Dot Density Map')\n",
    "plt.tight_layout\n",
    "# this will set the image width to 722px at 100dp\n",
    "fig.set_size_inches(7.22, 5.25)\n",
    "plt.savefig('Data/dot_density_map.png', dpi=100, alphe=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chloropleth Map - Density of Points by Ward\n",
    "\n",
    "Change titles to whatever is most appropriate for your own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a chloropleth map normalised by ward area\n",
    "#Add fields for denity into map dataframe\n",
    "\n",
    "df_map['count'] = df_map['poly'].map(lambda x: int(len(filter(prep(x).contains, ldn_points))))\n",
    "df_map['density_m'] = df_map['count']/df_map['area_m']\n",
    "df_map['density_km'] = df_map['count']/df_map['area_km']\n",
    "\n",
    "# it's easier to work with NaN values when classifying\n",
    "df_map.replace(to_replace={'density_m': {0: np.nan}, 'density_km': {0: np.nan}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#divide wards into classes\n",
    "breaks = nb(\n",
    "    df_map[df_map['density_km'].notnull()].density_km.values,\n",
    "    initial=300,\n",
    "    k=5)\n",
    "\n",
    "#The notnull method lets us match indices when joining\n",
    "jb = pd.DataFrame({'jenks_bins':breaks.yb}, index=df_map[df_map['density_km'].notnull()].index)\n",
    "df_map = df_map.join(jb)\n",
    "df_map.jenks_bins.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Labels for colour classes\n",
    "jenks_labels = [\"<=%0.1f/km$^2$(%s wards)\" % (b,c) for b, c in zip(\n",
    "    breaks.bins, breaks.counts)]\n",
    "jenks_labels.insert(0, 'No plaques (%s wards)' % len (df_map[df_map['density_km'].isnull()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cloropleth\n",
    "plt.clf()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, axisbg='w', frame_on=False)\n",
    "\n",
    "# use a blue colour ramp - we'll be converting it to a map using cmap()\n",
    "cmap = plt.get_cmap('Blues')\n",
    "# draw wards with grey outlines\n",
    "df_map['patches'] = df_map['poly'].map(lambda x: PolygonPatch(x, ec='#555555', lw=.2, alpha=1., zorder=4))\n",
    "pc = PatchCollection(df_map['patches'], match_original=True)\n",
    "# impose our colour map onto the patch collection\n",
    "norm = Normalize()\n",
    "pc.set_facecolor(cmap(norm(df_map['jenks_bins'].values)))\n",
    "ax.add_collection(pc)\n",
    "\n",
    "# Add a colour bar\n",
    "cb = colorbar_index(ncolors=len(jenks_labels), cmap=cmap, shrink=0.5, labels=jenks_labels)\n",
    "cb.ax.tick_params(labelsize=6)\n",
    "\n",
    "# Show highest densities, in descending order\n",
    "highest = '\\n'.join(\n",
    "    value[1] for _, value in df_map[(df_map['jenks_bins'] == 4)][:10].sort().iterrows())\n",
    "highest = 'Most Dense Wards:\\n\\n' + highest\n",
    "# Subtraction is necessary for precise y coordinate alignment\n",
    "details = cb.ax.text(\n",
    "    -1., 0 - 0.007,\n",
    "    highest,\n",
    "    ha='right', va='bottom',\n",
    "    size=5,\n",
    "    color='#555555')\n",
    "\n",
    "# Bin method, copyright and source data info\n",
    "smallprint = ax.text(\n",
    "    1.03, 0,\n",
    "    'Classification method: natural breaks etc',\n",
    "    ha='right', va='bottom',\n",
    "    size=4,\n",
    "    color='#555555',\n",
    "    transform=ax.transAxes)\n",
    "\n",
    "# Draw a map scale\n",
    "m.drawmapscale(\n",
    "    coords[0] + 0.08, coords[1] + 0.015,\n",
    "    coords[0], coords[1],\n",
    "    10.,\n",
    "    barstyle='fancy', labelstyle='simple',\n",
    "    fillcolor1='w', fillcolor2='#555555',\n",
    "    fontcolor='#555555',\n",
    "    zorder=5)\n",
    "\n",
    "# this will set the image width to 722px at 100dpi\n",
    "plt.tight_layout()\n",
    "fig.set_size_inches(7.22, 5.25)\n",
    "plt.savefig('data/choloropleth.png', dpi=100, alpha=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
